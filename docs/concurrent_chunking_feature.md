# 并发处理和文本分块功能说明

## 概述

本文档介绍了 Anki Feynman 插件新增的并发处理和文本分块功能。这些功能可以显著提升处理长文本时的性能，并支持更高效的 AI 请求处理。

## 功能特性

### 1. 并发处理

**作用**：允许同时发送多个 API 请求，加快处理速度。

**适用场景**：
- 文本被分成多块后，可以并发处理每一块
- 减少总体等待时间
- 特别适合处理长文本或生成大量题目

**配置参数**：
- `enable_concurrent_processing`: 是否启用并发处理（默认：false）
- `max_concurrent_requests`: 最大并发请求数（范围：1-10，默认：3）

**建议设置**：
- OpenAI API：建议设置为 3-5
- 自定义 API：根据服务商的限制调整
- 注意：过高的并发数可能触发 API 速率限制

### 2. 文本分块

**作用**：将长文本智能分割成多个块，分别处理后合并结果。

**适用场景**：
- 文本长度超过 3000 字符时自动启用
- 避免超过 AI 模型的 token 限制
- 提高长文本处理的成功率

**配置参数**：
- `enable_text_chunking`: 是否启用文本分块（默认：false）
- `chunk_size`: 每块的字符数（范围：500-8000，默认：2000）
- `chunk_overlap`: 重叠字符数（范围：0-1000，默认：200）
- `chunk_strategy`: 分块策略（"simple" 或 "smart"，默认："smart"）

**分块策略说明**：

#### 简单分块 (simple)
- 按固定字符数分割
- 处理速度快
- 可能在句子或段落中间分割

#### 智能分块 (smart)
- 在段落或句子边界分割
- 保持内容连贯性
- 更适合生成高质量的题目
- **推荐使用**

**重叠字符数的作用**：
- 在相邻分块之间保留一定的重复内容
- 确保上下文的连贯性
- 避免在分块边界处丢失信息

## 如何使用

### 1. 打开设置

在 Anki 中：Tools → Add-ons → Feynman Learning Method → Settings

### 2. 切换到"额外设置"标签页

在设置对话框中，选择第三个标签页："额外设置"

### 3. 配置并发处理

```
□ 启用并发处理
  └─ 最大并发请求数: [3] (1-10)
  
说明：启用后可同时发送多个API请求，加快处理速度。
建议根据API限制设置（如OpenAI建议3-5）。
```

### 4. 配置文本分块

```
□ 启用文本分块
  ├─ 分块大小（字符数）: [2000] (500-8000)
  ├─ 重叠字符数: [200] (0-1000)
  └─ 分块策略: [智能分块 ▼]
  
说明：长文本会被分成多块处理。智能分块会在段落/句子
边界分割，保持内容连贯性。
```

### 5. 保存设置

点击"保存"按钮，设置将立即生效。

## 工作流程

### 不使用分块和并发（默认）
```
[长文本] → [AI请求] → [生成结果]
```

### 使用分块但不并发
```
[长文本] → [分块1] → [AI请求1] → [结果1]
         → [分块2] → [AI请求2] → [结果2]  (顺序)
         → [分块3] → [AI请求3] → [结果3]
         → [合并结果]
```

### 使用分块和并发
```
[长文本] → [分块1] ┐
         → [分块2] ├→ [并发AI请求] → [结果1,2,3] → [合并结果]
         → [分块3] ┘
```

## 进度显示

启用分块和并发后，在生成问题时会在控制台显示进度信息：

```
文本长度 5000，启用分块处理
文本已分为 3 块
使用并发处理，最大并发数: 3
[进度] 1/3 - 正在处理分块 1/3
[进度] 2/3 - 正在处理分块 2/3
[进度] 3/3 - 正在处理分块 3/3
已合并 15 个问题
```

## 性能优化建议

### 1. 根据文本长度调整分块大小

| 文本长度 | 建议分块大小 | 原因 |
|---------|------------|------|
| < 3000 字符 | 不分块 | 不需要分块 |
| 3000-8000 | 2000-3000 | 平衡质量和速度 |
| > 8000 | 2000 | 避免超过token限制 |

### 2. 根据API限制调整并发数

| API 提供商 | 建议并发数 | 备注 |
|-----------|-----------|------|
| OpenAI | 3-5 | 官方建议 |
| Claude | 2-3 | 较保守 |
| 自定义API | 根据限制 | 咨询服务商 |

### 3. 重叠字符数设置

- 短文本（<5000字符）：100-150
- 中等文本（5000-10000）：150-200
- 长文本（>10000）：200-300

## 错误处理

### 自动降级

如果分块或并发处理失败，系统会自动降级：

1. 并发失败 → 回退到顺序处理
2. 分块失败 → 回退到单次完整处理
3. 记录错误日志便于调试

### 常见问题

**Q1: 启用并发后请求失败怎么办？**

A: 降低并发数。某些 API 有严格的速率限制。

**Q2: 分块后生成的题目质量下降？**

A: 
- 增加重叠字符数（如 250-300）
- 使用"智能分块"策略
- 适当增加分块大小

**Q3: 处理速度没有明显提升？**

A: 
- 检查是否启用了并发
- 确认文本长度足够需要分块
- 网络延迟可能是瓶颈

## 技术实现

### 核心组件

1. **TextChunker** (`utils/text_chunker.py`)
   - 智能和简单两种分块策略
   - 自动识别自然边界（段落、句子）
   - 结果合并功能

2. **ConcurrentProcessor** (`utils/concurrent_processor.py`)
   - 基于 ThreadPoolExecutor
   - 支持进度回调
   - 错误处理和重试

3. **AIHandler** (`utils/ai_handler.py`)
   - 集成分块和并发逻辑
   - 自动判断是否需要分块
   - 回退机制保证稳定性

### 应用范围

该功能已应用到以下所有生成场景：

- ✅ 选择题生成
- ✅ 问答题生成  
- ✅ 知识卡生成
- ✅ 自定义模板生成

## 配置文件示例

```json
{
  "advanced_settings": {
    "enable_concurrent_processing": true,
    "max_concurrent_requests": 3,
    "enable_text_chunking": true,
    "chunk_size": 2000,
    "chunk_overlap": 200,
    "chunk_strategy": "smart"
  }
}
```

## 注意事项

1. **API 费用**：并发请求会同时消耗 API 配额
2. **内存使用**：处理大文本时内存占用会增加
3. **稳定性**：建议先用小文本测试配置
4. **向后兼容**：默认关闭，不影响现有用户

## 更新日志

### v1.0.0 (2025-01-XX)
- 🎉 新增并发处理功能
- 🎉 新增文本分块功能
- 🎉 新增"额外设置"配置页面
- ✨ 支持智能和简单两种分块策略
- ✨ 添加进度回调和显示
- 🐛 自动降级和错误处理

## 反馈与支持

如遇到问题或有建议，请通过以下方式联系：
- GitHub Issues
- 插件设置页面的反馈链接

